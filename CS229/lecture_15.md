[<< Lecture 14](lecture_14.md) â€¢ [Lecture 16 >>](lecture_16.md)
## Lecture 15 - EM Algorithm & Factor Analysis

[![Lecture 15 - EM Algorithm & Factor Analysis | Stanford CS229: Machine Learning Andrew Ng -Autumn2018](https://markdown-videos-api.jorgenkh.no/url?url=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3Dtw6cmL5STuY%26list%3DPLoROMvodv4rMiGQp3WXShtMGgzqpfVfbU%26index%3D15)](https://www.youtube.com/watch?v=tw6cmL5STuY&list=PLoROMvodv4rMiGQp3WXShtMGgzqpfVfbU&index=15)

### Overview

### Timestamps
  
[0:27](https://youtu.be/tw6cmL5STuY?si=Xlbnl7Q7hzEEAZ6s&t=27): ğŸ“š The video discusses elaborations on the Expectation Maximization (EM) algorithm and introduces the factor analysis model.  
[6:03](https://youtu.be/tw6cmL5STuY?si=Xlbnl7Q7hzEEAZ6s&t=363): âœï¸ The video discusses the implementation of the Expectation-Maximization algorithm for a mixture of Gaussians model.  
[12:58](https://youtu.be/tw6cmL5STuY?si=Xlbnl7Q7hzEEAZ6s&t=778): âœ… The speaker discusses the difference between the mixture of Gaussians model and factor analysis model in the context of the EM algorithm.  
[20:23](https://youtu.be/tw6cmL5STuY?si=Xlbnl7Q7hzEEAZ6s&t=1223): ğŸ”¥ The video discusses modeling anomalies in temperature readings for energy conservation purposes.  
[26:22](https://youtu.be/tw6cmL5STuY?si=Xlbnl7Q7hzEEAZ6s&t=1582): ğŸ“Š The speaker discusses the limitations of a Gaussian model for certain datasets and introduces factor analysis as a more effective model.  
[32:03](https://youtu.be/tw6cmL5STuY?si=Xlbnl7Q7hzEEAZ6s&t=1923): ğŸ“Š The video discusses constraining the covariance matrix in Gaussian models to have circular contours.  
[42:18](https://youtu.be/tw6cmL5STuY?si=Xlbnl7Q7hzEEAZ6s&t=2538): ğŸ“š The video discusses a model with a diagonal matrix and conditional distribution.  
[48:03](https://youtu.be/tw6cmL5STuY?si=Xlbnl7Q7hzEEAZ6s&t=2538): ğŸ“Š The video explains the concept of a two-dimensional random sample and covariance matrix.  
[55:11](https://youtu.be/tw6cmL5STuY?si=Xlbnl7Q7hzEEAZ6s&t=3311): ğŸ“Š Modeling high dimensional data sets that do not lie on a low dimensional subspace can be challenging.  
[1:00:01](https://youtu.be/tw6cmL5STuY?si=Xlbnl7Q7hzEEAZ6s&t=3601): ğŸ“š The video discusses the marginal and conditional distributions of Gaussian random variables.  
[1:07:49](https://youtu.be/tw6cmL5STuY?si=Xlbnl7Q7hzEEAZ6s&t=4069): ğŸ“š The video explains the process of calculating the covariance matrix for a multivariate Gaussian distribution.  
[1:15:13](https://youtu.be/tw6cmL5STuY?si=Xlbnl7Q7hzEEAZ6s&t=4513): ğŸ“š The video explains a simpler way to compute an integral using the expected value of a random variable.

Timestamps by Tammy AI

[<< Lecture 14](lecture_14.md) â€¢ [Lecture 16 >>](lecture_16.md)