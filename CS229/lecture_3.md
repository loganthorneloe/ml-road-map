[<< Lecture 2](lecture_2.md) â€¢ [Lecture 4 >>](lecture_4.md)
## Lecture 3 - Locally Weighted and Logistic Regression

[![Locally Weighted & Logistic Regression | Stanford CS229: Machine Learning - Lecture 3 (Autumn 2018)](https://markdown-videos-api.jorgenkh.no/url?url=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3Dhet9HFqo1TQ%26list%3DPLoROMvodv4rMiGQp3WXShtMGgzqpfVfbU%26index%3D3)](https://www.youtube.com/watch?v=het9HFqo1TQ&list=PLoROMvodv4rMiGQp3WXShtMGgzqpfVfbU&index=3)

### Topics

* Locally Weighted Regression
* Logistic Regression
* Gaussian Density
* Maximum Likelihood Estimation

### Timestamps

[0:28](https://youtu.be/het9HFqo1TQ?si=Mz6Fi-UvHLYq08Ls&t=28): ğŸ“š The video discusses supervised learning, specifically linear regression, locally weighted regression, and logistic regression.  
[5:38](https://youtu.be/het9HFqo1TQ?si=Mz6Fi-UvHLYq08Ls&t=338): ğŸ“š Locally weighted regression is a non-parametric learning algorithm that requires keeping data in computer memory.  
[13:05](https://youtu.be/het9HFqo1TQ?si=Mz6Fi-UvHLYq08Ls&t=785): ğŸ“Š Locally weighted regression is a method that assigns different weights to data points based on their distance from the prediction point.  
[19:01](https://youtu.be/het9HFqo1TQ?si=Mz6Fi-UvHLYq08Ls&t=1141): ğŸ“š Locally linear regression is a learning algorithm that may not have good results and is not great at extrapolation.  
[24:46](https://youtu.be/het9HFqo1TQ?si=Mz6Fi-UvHLYq08Ls&t=1486): ğŸ” The video discusses Gaussian density and its application in determining housing prices.  
[31:31](https://youtu.be/het9HFqo1TQ?si=Mz6Fi-UvHLYq08Ls&t=1891): ğŸ’¡ The likelihood of the parameters is the probability of the data given the parameters, assuming independent and identically distributed errors.  
[36:55](https://youtu.be/het9HFqo1TQ?si=Mz6Fi-UvHLYq08Ls&t=2215): ğŸ“Š Maximum Likelihood Estimation (MLE) is a commonly used method in statistics to estimate parameters by maximizing the likelihood or log-likelihood of the data.  
[43:44](https://youtu.be/het9HFqo1TQ?si=Mz6Fi-UvHLYq08Ls&t=2624): ğŸ“Š Applying linear regression to a binary classification problem is not a good idea.  
[49:22](https://youtu.be/het9HFqo1TQ?si=Mz6Fi-UvHLYq08Ls&t=2962): ğŸ¯ The video discusses the choice of hypothesis function in learning algorithms and why logistic regression is chosen as a special case of generalized linear models.  
[54:45](https://youtu.be/het9HFqo1TQ?si=Mz6Fi-UvHLYq08Ls&t=3285): ğŸ“š The video explains how to compress two equations into one line using a notational trick.  
[1:01:31](https://youtu.be/het9HFqo1TQ?si=Mz6Fi-UvHLYq08Ls&t=3691): âœï¸ Batch gradient ascent is used to update the parameters in logistic regression.  
[1:07:52](https://youtu.be/het9HFqo1TQ?si=Mz6Fi-UvHLYq08Ls&t=4072): ğŸ“š The video explains how to use Newton's method to find the maximum or minimum of a function.  
[1:13:55](https://youtu.be/het9HFqo1TQ?si=Mz6Fi-UvHLYq08Ls&t=4435): ğŸ’¡ Newton's method is a fast algorithm for finding the place where the first derivative of a function is 0, using the first and second derivatives.  
  
Timestamps by Tammy AI

[<< Lecture 2](lecture_2.md) â€¢ [Lecture 4 >>](lecture_4.md)