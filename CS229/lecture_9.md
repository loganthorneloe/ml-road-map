[<< Lecture 8](lecture_8.md) â€¢ [Lecture 10 >>](lecture_10.md)
## Lecture 9 - Approx/Estimation Error & ERM

[![Lecture 9 - Approx/Estimation Error & ERM | Stanford CS229: Machine Learning (Autumn 2018)](https://markdown-videos-api.jorgenkh.no/url?url=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DiVOxMcumR4A%26list%3DPLoROMvodv4rMiGQp3WXShtMGgzqpfVfbU%26index%3D9)](https://www.youtube.com/watch?v=iVOxMcumR4A&list=PLoROMvodv4rMiGQp3WXShtMGgzqpfVfbU&index=9)

### Overview

### Timestamps
  
[0:11](https://youtu.be/iVOxMcumR4A?si=OXRhekL2cZU7iUlF&t=11): ğŸ“ The video covers learning theory and its importance in understanding machine learning.  
[8:05](https://youtu.be/iVOxMcumR4A?si=OXRhekL2cZU7iUlF&t=485): ğŸ‘ Linear regression can be a vector, scalar, or matrix that is estimated through a generic function, and underfitting and overfitting are related to bias and variance.  
[16:07](https://youtu.be/iVOxMcumR4A?si=OXRhekL2cZU7iUlF&t=967): ğŸ“Š Increasing the size of the data can decrease the variance of theta hat in machine learning algorithms.  
[22:54](https://youtu.be/iVOxMcumR4A?si=OXRhekL2cZU7iUlF&t=1374): ğŸ“š Bias and variance are two important concepts in machine learning that can affect the performance of an algorithm.  
[30:55](https://youtu.be/iVOxMcumR4A?si=OXRhekL2cZU7iUlF&t=1855): ğŸ’¡ The video discusses the concept of error in machine learning and its different types.  
[39:27](https://youtu.be/iVOxMcumR4A?si=OXRhekL2cZU7iUlF&t=2367): ğŸ“š Adding regularization helps reduce variance by shrinking the class of hypothesis.  
[46:31](https://youtu.be/iVOxMcumR4A?si=OXRhekL2cZU7iUlF&t=2791): ğŸ“š The video discusses empirical risk minimization and its relationship to bias-variance theory.  
[55:40](https://youtu.be/iVOxMcumR4A?si=OXRhekL2cZU7iUlF&t=3340): ğŸ“š Hoeffding's inequality states that the probability of an estimate deviating more than a certain margin reduces as the number of repetitions increases.  
[1:02:39](https://youtu.be/iVOxMcumR4A?si=OXRhekL2cZU7iUlF&t=3759): ğŸ“š The video discusses the generalization error and empirical error in machine learning and how they relate to Hoeffding's Inequality.  
[1:11:31](https://youtu.be/iVOxMcumR4A?si=OXRhekL2cZU7iUlF&t=4291): ğŸ“š The video discusses the probability of the empirical error minus generalization error being greater than a certain value in finite and infinite hypothesis classes.  
[1:20:03](https://youtu.be/iVOxMcumR4A?si=OXRhekL2cZU7iUlF&t=4803): ğŸ“š The video discusses the relationship between empirical error and generalization error in machine learning.  

Timestamps by Tammy AI

[<< Lecture 8](lecture_8.md) â€¢ [Lecture 10 >>](lecture_10.md)